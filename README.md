# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #1 выполнил(а):
- Гилязов Арсель Мирасович
- РИ210950
Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 60 |
| Задание 2 | * | 20 |
| Задание 3 | * | 20 |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

Структура отчета

- Данные о работе: название работы, фио, группа, выполненные задания.
- Цель работы.
- Задание 1.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 2.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 3.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Выводы.
- ✨Magic ✨

## Цель работы
Познакомиться с программными средствами для создания системы машинного обучения и ее интеграции в Unity.

## Задание 1
### Реализовать систему машинного обучения в связке Python - Google-Sheets – Unity. 
Ход работы:
- Созданы объекты куб, шар, плоскость, так же созданы для них материалы
![image](https://user-images.githubusercontent.com/103649799/198530109-8a4c2c73-ad39-404b-9419-157fa68beae3.png)
- Скачаны необходимые пакеты для юнити, параллельно с этим в анаконде созано окружение, и закачены модули
![image](https://user-images.githubusercontent.com/103649799/198530284-04f17c71-63f3-4e31-8d71-f561ecefa467.png)
- Создан скрипт для сферы, и подключены все необходимые компоненты для сферы
![image](https://user-images.githubusercontent.com/103649799/198530645-9793a885-072c-4f90-bd71-ef1dfb85d7cb.png)
- В папку с проектом добавляем файл конфигурации нейронной сети
![image](https://user-images.githubusercontent.com/103649799/198531111-59104f5c-24c5-4ee3-8c22-9530d205f0d3.png)
- Соединяем конду с юнити и запускаем работу агента
![image](https://user-images.githubusercontent.com/103649799/198531600-6fe84dad-3021-42dd-b44e-6613555ec289.png)
- Запускаем сцену в юнити, удостоверяемся что шарик бегает и все работает
![image](https://user-images.githubusercontent.com/103649799/198531664-e0f0717f-9d6f-4e30-917c-a5dda39f6d43.png)
- Отчет работы агента
![image](https://user-images.githubusercontent.com/103649799/198531743-cf953baa-07e3-418e-83c3-3548e9eea918.png)
- Создадим несколько копий сцен, чтобы обучение шло активнее, если точно то 256 копий
![image](https://user-images.githubusercontent.com/103649799/198533026-5891fc86-c312-49e1-8325-ed0d0bcabd0b.png)
- Выполнено 120к шагов
![image](https://user-images.githubusercontent.com/103649799/198537446-d2fb52df-2d71-466f-940b-a109d8c88c71.png)
- Переносим файл .onnx из появившейся папки результат
![image](https://user-images.githubusercontent.com/103649799/198537809-2a344f23-dc3c-4a49-a694-49adcdb7561b.png)
- Загружаем этот файл в модель behavior parameters и запускаем сцену, теперь шарик движется за кубом, за счет долгого обучения шарик резко разворачивается и не падает за края
![image](https://user-images.githubusercontent.com/103649799/198539064-6d71e345-3413-4ff8-b192-f23c28e52cf8.png)

### Вывод
После этого задания я научился связывать юнити со средствами машинного обучения, выявил для себя проблемы, которые можно решить с помощью ML агента, так же научился обучать этого умного агента

## Задание 2
### Подробно опишите каждую строку файла конфигурации нейронной сети.
Ход работы:
- Опишем каждую строчку из файла конфигурации нейросети

1. Описание поведения
2. Объект который описывают
3. Тип тренера
4. Далее задаются параметры : размер партии, размер буфера, скорость обучения и другие постоянные
5. Задаются сетевые настройки: необходмо ли нормализовывать, количесвто слоев и скрытых юнитов
6. наградные сигналы
7. Максимальное количество шагов обучения
8. Время данное на обучение
9. Суммарная частота

- Опишем компоненты DecisionRequester и Behavior Parameters которые мы накладывали на нашего агента

Компонент DecisionRequester предоставляет удобный и гибкий способ запуска процесса принятия решения агентом. Без DecisionRequester реализация вашего агента должна вручную вызывать функцию RequestDecision().

Во время выполнения Behavior Parameters генерирует объекты политики агента в соответствии с настройками, указанными в редакторе.

## Задание 3
### Доработайте сцену и обучите ML-Agent таким образом, чтобы шар перемещался между двумя кубами разного цвета. Кубы должны, как и в первом задании, случайно изменять координаты на плоскости. 
Ход работы:
-Создаем еще один куб и переписываем скрипт для двух целей
![image](https://user-images.githubusercontent.com/103649799/198831623-fada6265-2bc4-47c0-bf79-b42a4e47d496.png)
![image](https://user-images.githubusercontent.com/103649799/198831256-e8c10df4-94b1-4166-929a-d8cb900e06bb.png)
- Заново обучаем наш шар
![image](https://user-images.githubusercontent.com/103649799/198831055-11ede788-a90d-4f24-83af-9190528628d6.png)
![image](https://user-images.githubusercontent.com/103649799/198831245-4b47b4f9-5402-46d0-97f4-bee0b8ecc5ab.png)
- Добавляем модель поведения шару и проверяем
![image](https://user-images.githubusercontent.com/103649799/198831965-63cefac9-80bb-44b2-af9b-2410861c6979.png)

Как видим все хорошо работает


## Выводы

Обычно на выявление дисбаланса в новых прототипах игр требуются месяцы плейтестинга. При использовании систем машинного обучения можно не только выявить потенциальные источники дисбаланса, но и за считанные дни внести изменения, позволяющие смягчить их воздействие. Я выяснил, что относительно простой нейронной сети достаточно, чтобы достичь высокой эффективности в принятии решений в играх. Таких агентов можно использовать различными способами, например, для тренировки новых игроков или для выявления неожиданных стратегий.


| Plugin | README |
| ------ | ------ |
| Dropbox | [plugins/dropbox/README.md][PlDb] |
| GitHub | [plugins/github/README.md][PlGh] |
| Google Drive | [plugins/googledrive/README.md][PlGd] |
| OneDrive | [plugins/onedrive/README.md][PlOd] |
| Medium | [plugins/medium/README.md][PlMe] |
| Google Analytics | [plugins/googleanalytics/README.md][PlGa] |

## Powered by

**BigDigital Team: Denisov | Fadeev | Panov**
